## ğŸ¤– AI Engineer in the Making

<h1 align="center">
  <img src="https://readme-typing-svg.herokuapp.com?size=28&color=00F5FF&center=true&vCenter=true&width=600&lines=Computer+Engineer&repeat=false" />
</h1>

<h2 align="center">
  <img src="https://readme-typing-svg.herokuapp.com?size=20&color=FFD21E&center=true&vCenter=true&width=700&lines=ML+Â·+DL+Â·+NLP+Â·+Transformers+Â·+LLMs&repeat=false" />
</h2>

---

## ğŸ§  About Me

I am a **Computer Engineer** diving deep into **Artificial Intelligence**,  
focused on understanding how machines **learn, reason, and understand language**.

I prioritize **strong fundamentals**, **hands-on implementation**, and  
**model internals** instead of treating AI as a black box.

ğŸ’» Primary language: **Python**  
ğŸ§ª Approach: **Theory + Practice**

---

## ğŸ§¬ AI Skills Matrix

<h3>ğŸ Programming</h3>

ğŸ”¹ Python  
ğŸ”¹ C++  

<h3>ğŸ§  Machine Learning</h3>

ğŸŸ¦ Supervised Learning  
ğŸŸ© Unsupervised Learning  
ğŸŸ¨ Model Training  
ğŸŸª Model Evaluation  

<h3>ğŸ”¥ Deep Learning</h3>

ğŸŸ¥ Neural Networks  
ğŸŸ§ Convolutional Neural Networks (CNNs)  
ğŸŸ¦ Recurrent Neural Networks (RNNs)  
ğŸŸ© Backpropagation  

<h3>ğŸ—£ï¸ Natural Language Processing</h3>

ğŸŸ£ Text Preprocessing  
ğŸŸ¦ Tokenization  
ğŸŸ¨ Word & Sentence Embeddings  

<h3>ğŸ”— Transformers & LLMs</h3>

ğŸŸ  Attention Mechanism  
ğŸŸ¦ Encoderâ€“Decoder Architecture  
âš« Large Language Models (LLMs)  
ğŸŸ¢ Prompt Engineering  

---

## ğŸ› ï¸ Tools & Frameworks

ğŸ§© NumPy  
ğŸ“Š Pandas  
ğŸ§  Scikit-Learn  
ğŸ”¥ PyTorch  
âš™ï¸ TensorFlow  
ğŸ¤— Hugging Face  

---

## âš™ï¸ Currently Working On

ğŸ§  Strengthening ML & DL fundamentals  
ğŸ—£ï¸ Building NLP pipelines  
ğŸ”— Understanding Transformer internals  
ğŸ¤– Exploring Large Language Models  
ğŸ§ª Python-based AI experiments  

---

<h3 align="center">
  <img src="https://readme-typing-svg.herokuapp.com?size=16&color=00F5FF&center=true&vCenter=true&width=800&lines=Building+intelligence+from+fundamentals+â€”+not+treating+AI+as+a+black+box.&repeat=false" />
</h3>
